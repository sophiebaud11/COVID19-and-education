---
title: "clean_data.Rmd"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(totalcensus)
library(maps)
library(gganimate)
library(lubridate)
library(rstanarm)
library(tidymodels)
library(gtsummary)
library(broom.mixed)
library(gt)
library(rsample)
# Load the package
library(nnet)

```
TO DO BEFORE HANDING IN:
* upload all data to github
* keep finessing the model
* add github link to about page

# Load Data

```{r}

# school covid restriction data from randomly selected districts

covid_restrictions <- read.csv("raw_data/covid_restrictions.csv") %>%
  filter(covid.restriction == -1 | covid.restriction == 0 | 
           covid.restriction == 1) %>%
  mutate(date = mdy(date))

samples <- read.csv("raw_data/sample_districts_edited.csv")

sample_counties_covid_nyt <- read.csv("raw_data/us-counties.csv") %>%
  filter(fips %in% samples$fips_code) %>%
  mutate(date = as_date(date)) %>%
  filter(date > ymd(20200731))
  
final_sample_data <- merge(covid_restrictions, sample_counties_covid_nyt, 
                               by = c("date", "county")) %>%
  select(-c(fips_code, state.y, )) %>%
  rename(state = "state.x",
         fips_code = "fips") %>%
  merge(., county_pop_with_fips, by = "fips_code") %>%
  mutate(cases_per_capita = cases / POPESTIMATE2019,
         covid.restriction = as.numeric(covid.restriction))

final_sample_data_binomial <- final_sample_data %>%
  mutate(covid.restriction = ifelse(covid.restriction == -1, 
                                    0, covid.restriction))

    
saveRDS(final_sample_data, file = "final_sample_data.RDS")
# school district data source Steven Manson, Jonathan Schroeder, David Van Riper, Tracy Kugler, and Steven Ruggles. IPUMS National Historical Geographic Information System: Version 15.0 [dataset]. Minneapolis, MN: IPUMS. 2020. http://doi.org/10.18128/D050.V15.0 / IPUMS NHGIS, University of Minnesota, www.nhgis.org (2014-2018)

district_uni  <- read.csv("raw_data/districts_uni.csv") %>%
  select(c(GISJOIN, STATE, STATEA, SDUNI, SDUNIA, AJWME001, AJWMM001))

# replace initial size 50 sample with a sample of 7 to replace the 7
# districts that didn't fit into counties

sample_districts_GIS_extra <- sample(district_uni$GISJOIN, size = 7, replace = FALSE)

sample_districts_extra <- district_uni %>%
  filter(GISJOIN %in% sample_districts_GIS_extra) 

# combine first and second samples

sample_districts <- district_uni %>%
  filter(GISJOIN %in% sample_districts_GIS) %>%
  rbind(., sample_districts_extra)

# remove the wonky districts

sample_districts <- sample_districts[-c(11, 18, 20, 22, 23, 37, 38), ]

# add county fips codes so you can graph it

sample_districts <- sample_districts %>%
  mutate(fips_code = c(1043, 8081, 9013, 13037, 16027, 
                         17043, 19193, 19121, 20019, 23005,
                         25015, 26021, 28087, 28047, 28149,
                         29033, 29183, 31055, 34003, 34027,
                         34009, 36103, 36077, 36079, 36059,
                         38031, 39031, 39051, 40079, 40113,
                         40019, 42037, 42075, 42085, 46033,
                         48439, 48347, 48029, 53077, 53065,
                         53005, 55045, 55029, 13269, 18039,
                         26093, 26017, 31097, 39145, 48097)) %>%
  left_join(., fips_codes, by = "fips_code") 
sample_districts_edited <- sample_districts %>%
  mutate(county = tolower(county)) %>%
  rename(subregion = "county") %>%
  mutate(state_county = tolower(paste(STATE, subregion, sep = "")))

# average annual teacher salary by state (2018-2019) data source: 
# https://nces.ed.gov/programs/digest/d19/tables/dt19_211.60.asp

avg_salary_2018 <- read.csv("raw_data/avg_teacher_salary.csv")


#county data from: Quarterly Census of Employment and Wages (https://data.bls.gov/cew/apps/table_maker/v4/table_maker.htm#type=1&year=2020&qtr=1&own=3&ind=6111&supp=0)

county_data <- read.csv("raw_data/county_wages.csv")

# source: https://www.nrcs.usda.gov/wps/portal/nrcs/detail/national/home/?cid=nrcs143_013697

state_names <- tibble(state.abb, state.name) %>%
  rename(state = "state.abb")

fips_codes <- read.csv("raw_data/fips_codes.csv") %>%
  left_join(., state_names, by = "state")

# covid-19 case count by state source: https://github.com/nytimes/covid-19-data.

covid_nytimes <- read.csv("raw_data/covid_nytimes.csv")

# covid-19 case count by county source: 
# https://github.com/nytimes/covid-19-data. separate csv file into multiple
# columns.

county_covid_nyt <- read.csv("raw_data/us-counties.csv")

# state population as of July 2019 data source:
# https://www.census.gov/data/datasets/time-series/demo/popest/2010s-state-total
# .html#par_textimage_500989927

state_pop <- read.csv("raw_data/state_pop.csv")

# 2019 county populations (estimated) from:
# https://www.census.gov/data/datasets/time-series/demo/popest/2010s-counties-
# total.html#par_textimage_70769902.

county_pop <- read.csv("raw_data/census_county_population.csv")

# more data I'll probably use:
# Ipsos/NPR Survey on teachers during COVID-19:
# https://www.ipsos.com/sites/default/files/ct/news/documents/2020-08/
# topline-npr-teachers-covid-poll-080620.pdf
# school outbreak data:
# https://www.nytimes.com/interactive/2020/09/21/us/covid-schools.html


# IGNORE
wages_q1_2020 <- read.csv("raw_data/6111.csv") 
```

# Model


```{r}
data(state)
final_sample_data_binomial %>%
  mutate(region = which(state.name == state.region))
regions <- tibble(state.name, state.region) %>%
  rename(state = "state.name") %>%
  mutate(state.region = ifelse(state.region == "North Central", "Midwest", as.character(state.region)))

final_fit_data <- left_join(final_sample_data_binomial, regions, 
                            by = "state") %>%
  rename(`COVID Rate` = "rate",
         Region = "state.region")

set.seed(9)

fit2 <- stan_glm(formula = covid.restriction ~ `COVID Rate` + Region - 1,
                 data = final_fit_data,
                 family = binomial(),
                 refresh = 0)

saveRDS(fit2, "fit.RDS")

saveRDS(final_sample_data_binomial, "final_sample_data.RDS")

final_sample_data_binomial <- final_sample_data_binomial %>%
  group_by(county) %>% 
  arrange(county, date) %>% 
  mutate(rate = 100 * 
           (cases_per_capita - lag(cases_per_capita))/lag(cases_per_capita)) %>%
  ungroup()

# measure rate of change of covid cases by day/week/two weeks as a predictor 
state.region
set.seed(9)

fit1 <- stan_glm(formula = covid.restriction ~ cases_per_capita + 
                   presidential.results - 1,
                 data = final_sample_data_binomial,
                 family = binomial(),
                 refresh = 0)
print(fit1, digits = 5)

fit2 <- stan_glm(formula = covid.restriction ~ rate + 1,
                 data = final_sample_data_binomial,
                 family = binomial(),
                 refresh = 0)
print(fit2, digits = 5)

mean(final_sample_data_binomial$rate, na.rm = TRUE)

#exp(intercept OR trump/biden if -1  + Median for predictor*(case per capita #number))/(1+exp(intercept OR trump/biden if -1  + Median for predictor*(case per capita 
# number)) this calculates P(Y = 1) (aka fully remote)
                                                                                      
exp(-2.40324 + (-0.34339 * (0.01))) / (1 + exp(-2.40324 + (-0.34339 * (0.01))))
                                                                                      
# P(Y = 1) (fully remote chance) if rate of covid change is the mean: 0.05464674
```

```{r}
tbl_regression(fit1, intercept = FALSE) %>% 
  as_gt() %>%
  tab_header(title = "Regression of Public School COVID Restrictions",
             subtitle = 
               " per Capita and Presidential Results on Restrictions") %>% 
  tab_source_note(md("Source: NY Times, local school websites."))

tbl_regression(fit2, intercept = FALSE) %>% 
  as_gt() %>%
  tab_header(title = "Regression of Public School COVID Restrictions",
             subtitle = 
               " per Capita and Presidential Results on Restrictions") %>% 
  tab_source_note(md("Source: NY Times, local school websites."))


new <- tibble(presidential.results = c("Trump", "Biden"),
              cases_per_capita = c(0.0211374, 0.0211374))

# create posterior distributions for both north & not-north rows, based on the
# model we created above. then turn the output of posterior_predict into
# an entirely numeric tibble.

post_pred <- posterior_predict(fit1,
                               newdata = new) %>%
  as_tibble() %>%
  mutate_all(as.numeric)

```



```{r}


sample_split <- initial_split(final_sample_data_binomial, prob = 0.80)
sample_train <- training(sample_split)
sample_test <- testing(sample_split)


# create recipe
sample_recipe <- recipe(formula = covid.restriction ~ cases_per_capita + 
                   presidential.results + deaths,
       data = final_sample_data) %>%
  step_dummy(all_nominal()) 
# create model
lm_model <- linear_reg() %>%
  set_engine("lm")
# create workflow + add recipe to it
lm_wflow <-
  workflow() %>%
  add_model(lm_model) %>%
  add_recipe(sample_recipe)

lm_fit <- fit(lm_wflow, sample_train)

sample_res <- predict(lm_fit, new_data= sample_test)

prediction_results <- bind_cols(sample_test, sample_res) %>%
  mutate(error = (covid.restriction - .pred)^2) %>%
  summarise(error = sqrt(mean(error, na.rm = TRUE)))

saveRDS(final_sample_data_binomial, "binomial_data.RDS")

```


# Clean Data

## County Data

```{r}

county_data_edited <- county_data %>%
  slice(1:5444) %>%
  filter(own_code != 5) %>%
  select(c(area_fips, avg_wkly_wage, own_code)) %>%
  rename(fips_code = "area_fips") %>%
  mutate(fips_code = as.numeric(fips_code),
         avg_wkly_wage = as.numeric(avg_wkly_wage)) %>%
  left_join(., fips_codes, by = "fips_code") %>%
  mutate(avg_wkly_wage = na_if(avg_wkly_wage, 0),
         county = tolower(county)) %>%
  drop_na() %>%
  rename(subregion = "county") %>%
  mutate(state_county = tolower(paste(state.name, subregion, sep = "")))

county_wage_data <- county_data_edited %>%
  group_by(state_county) %>%
  summarize(avg_wkly_wage_all = mean(avg_wkly_wage), .groups = "drop")
  

# clean county population data 

county_pop_edited <- county_pop %>%
  filter(str_detect(CTYNAME, "County") | str_detect(CTYNAME, "Parish")) %>%
  rename(state = "STNAME") %>%
  mutate(subregion = if_else(str_detect(CTYNAME, "County"),  
                             tolower(trimws(gsub("County", "", CTYNAME))), 
         tolower(trimws(gsub("Parish", "", CTYNAME)))))%>%
  mutate(state_county = tolower(paste(state, subregion, sep = "")))

county_fips <- fips_codes %>%
  mutate(state_county = tolower(paste(state.name, county, sep = "")))

county_pop_with_fips <- merge(county_fips, county_pop_edited, by = "state_county") %>%
  select(fips_code, POPESTIMATE2019, state_county)



# clean & wrangle covid case count per county data the same way I wrangled
# the state data!

county_covid_edited <- county_covid_nyt %>%
  mutate(subregion = tolower(county),
         cases = as.numeric(cases),
         deaths = as.numeric(deaths),
         state = tolower(state)) %>%
  mutate(state_county = tolower(paste(state, subregion, sep = ""))) %>%
  group_by(state_county) %>%
  filter(date == "2020-11-29") %>%
  select(-c(county, state)) %>%
  full_join(., county_pop_edited, by = "state_county") %>%
  drop_na() %>%
  rename(pop = "POPESTIMATE2019",
         region = "state") %>%
  mutate(cases_per_capita = cases/pop) %>%
  select(-c(CTYNAME))

  
  summarize(total_cases = sum(cases), total_deaths = sum(deaths), 
            .groups = "drop") %>%
  
# sample 50 random counties and get the school districts for those counties
# rep = 2 to account for cases in which the school district doesn't have info
# online; then create an excel file w measures: class type (inperson/online/
# hybrid), number of students, county population & how much of the county the
# school district makes up, covid cases per county, county avg weekly wage for 
# teachers
county_sample <- sample(county_wage_data$state_county, size = 50, replace = FALSE)

county_sample
```

## State Data

```{r}

# clean average teacher salary data 

avg_teacher_sal_edited <- avg_salary_2018 %>%
  
  # make all rows of the state column lowercase and get rid of any whitespace
  # at the head or tail to make sure it can join with the state_map dataset.
  
  mutate(region = tolower(trimws(state)),
         
         # get rid of commas in the value column so it can later be turned into
         # a numeric column.
         
         value = gsub(",", "", value)) %>%
  mutate(value = as.numeric(value)) %>%
  
  # arrange alphabetically so the join process with state_map is seamless.
  
  arrange(region) %>%
  
  # get rid of extraneous columns.
  select(-c(X, state))

# clean state population data

state_pop <- state_pop %>%
  
  # get rid of the weird period that for some reason starts every row in state
  # and rename the column to region.
  
  mutate(region = tolower(str_remove((state), "[[:punct:] ]+")))

# clean covid data

covid_nyt_with_pop <- covid_nytimes %>%
  
  # make the state column lowercase and rename it so it can join with 
  # states_map.
  
  mutate(region = tolower(state)) %>%
  group_by(region) %>%
  
  # collapse the dataset so each state has a total_cases and total_deaths
  # variable made up of the sum of the cases & deaths columns.
  
  summarize(total_cases = sum(cases), total_deaths = sum(deaths), 
            .groups = "drop") %>%
  
  # join with the state_pop tibble.
  
  full_join(., state_pop, by = "region") %>%
  drop_na() %>%
  rename(pop = "X2019_pop") %>%
  
  # convert the population column to numeric by getting rid of commas and then
  # running as.numeric().
  
  mutate(pop = gsub(",", "", pop)) %>%
  mutate(pop = as.numeric(pop)) %>%
  
  # create a cases_per_capita column which consists of the total cases in each 
  # state divided by its population, to better visualize the covid-19 data.
  
  mutate(cases_per_capita = total_cases/pop)

# INGORE THIS NEXT BLOCK OF CODE - I'm still deciding whether or not I want to 
# use this data!

wages_q1_2020_edited <- wages_q1_2020 %>%
  select(area_fips, avg_wkly_wage, own_code, lq_avg_wkly_wage) %>%
  slice(1:5444) %>%
  mutate(area_fips = as.numeric(area_fips)) %>%
  filter((area_fips %% 1000) == 0) %>%
  mutate(area_fips = area_fips / 1000,
         area_fips = case_when(area_fips < 10  ~ paste("0", 
                                                       as.character(area_fips),
                                                       sep = ""),
                               TRUE ~ as.character(area_fips)),
         area_name = convert_fips_to_names(area_fips)) %>%
  group_by(area_name, area_fips) %>%
  summarize(avg_ann_wage_all = mean(avg_wkly_wage * 52),
            lq_avg_wkly_wage_all = mean(lq_avg_wkly_wage), 
            .groups = "drop") %>%
  mutate(region = map(area_name,
                                ~ 
                        tolower(state.name[which(state.abb == .)]))) %>%
  filter(area_fips != "11" & area_fips != "72" & area_fips!= "78") %>%
  unnest(region)

```

# Plots:

```{r}

# load states_map & county_map data so I can map my tibbles.

county_map <- map_data("county") %>%
  mutate(state_county = tolower(paste(region, subregion, sep = ""))) 

states_map <- map_data("state")

# join the salary data and states_map data by region, so that the salary data
# for each state can be mapped to all of the necessary latitutes / longitudes.
# also, deselect unnecssary columns!

salary_map <- left_join(states_map, avg_teacher_sal_edited, by = "region") %>%
  select(-c(subregion))

# do the same for the covid data.

covid_map <- left_join(states_map, covid_nyt_with_pop, by = "region") %>%
  select(-c(subregion))

county_covid_map <- left_join(county_map, county_covid_edited, 
                              by = "state_county")

# do the same for the county wage data

county_wage_map <- left_join(county_map, county_wage_data, 
                             by = c("state_county"))

wages_map <- left_join(states_map, wages_q1_2020_edited, by = "region")

# write the salary, sample, and covid data to csv files so they can be accessed 
# in Shiny.

write_csv(county_wage_map, "raw_data/county_wage_map.csv")
write_csv(county_covid_map, "county_covid_map.csv")
write_csv(sample_districts_edited, "raw_data/sample_districts_edited.csv")
write_csv(tibble(Districts = sample_districts_edited$SDUNI,
                 County = str_to_title(sample_districts_edited$subregion)), 
          "raw_data/sample_districts_table.csv")

# plot county covid and wage maps!


county_covid_map %>%
  ggplot(aes(long, lat, group = group)) + 
  geom_polygon(aes(fill = cases_per_capita)) + theme_void() +
  scale_fill_viridis_c(direction = -1, option = "A", name = "Cases per Capita",
                       na.value = "white") + 
  theme(plot.background = element_rect(fill = "#c4c4c4"), 
        legend.position = "bottom",
        plot.title = element_text(color = "white", face = "bold"),
        plot.caption = element_text(color = "white", face = "bold"),
        legend.text = element_text(color = "white", face = "bold"),
        legend.title = element_text(color = "white", face = "bold")) + labs(
    title = " Total COVID-19 Cases per Capita by County, as of 10/16", 
    caption = "Source: New York Times ")


county_wage_map %>%
  ggplot(aes(long, lat, group = group)) +
  geom_polygon(aes(fill = avg_wkly_wage_all)) + theme_void() +
  scale_fill_viridis_c(direction = -1, option = "D", name = "Weekly Wage",
                       na.value = "white") + 
  theme(plot.background = element_rect(fill = "#c4c4c4"), 
        legend.position = "bottom",
        plot.title = element_text(color = "white", face = "bold"),
        plot.caption = element_text(color = "white", face = "bold"),
        legend.text = element_text(color = "white", face = "bold"),
        legend.title = element_text(color = "white", face = "bold")) + labs(
    title = " Average Weekly Wages for Educators per County", 
    caption = "Source: Bureau of Labor Statistics ")

# plot sampled maps

county_covid_map %>%
  mutate(cases_per_capita = ifelse(state_county %in% county_sample,
                                     cases_per_capita, NA)) %>%
  ggplot(aes(long, lat, group = group)) + 
  geom_polygon(aes(fill = cases_per_capita)) + theme_void() +
  scale_fill_viridis_c(direction = -1, option = "A", name = "Cases per Capita",
                       na.value = "white") + 
  theme(plot.background = element_rect(fill = "#c4c4c4"), 
        legend.position = "bottom",
        plot.title = element_text(color = "white", face = "bold"),
        plot.subtitle = element_text(color = "white", face = "bold"),
        plot.caption = element_text(color = "white", face = "bold"),
        legend.text = element_text(color = "white", face = "bold"),
        legend.title = element_text(color = "white", face = "bold")) + labs(
    title = " Total COVID-19 Cases per Capita by County, as of 10/16", 
    subtitle = " Limited to Sampled Counties",
    caption = "Source: New York Times ")


county_wage_map %>%
  mutate(avg_wkly_wage_all = ifelse(state_county %in% county_sample,
                                     avg_wkly_wage_all, NA)) %>%
  ggplot(aes(long, lat, group = group)) +
  geom_polygon(aes(fill = avg_wkly_wage_all)) + theme_void() +
  scale_fill_viridis_c(direction = -1, option = "D", name = "Weekly Wage",
                       na.value = "white") + 
  theme(plot.background = element_rect(fill = "#c4c4c4"), 
        legend.position = "bottom",
        plot.title = element_text(color = "white", face = "bold"),
        plot.subtitle = element_text(color = "white", face = "bold"),
        plot.caption = element_text(color = "white", face = "bold"),
        legend.text = element_text(color = "white", face = "bold"),
        legend.title = element_text(color = "white", face = "bold")) + labs(
    title = " Average Weekly Wages for Educators per County", 
    subtitle = " Limited to Sampled Counties",
    caption = "Source: Bureau of Labor Statistics ")

# NEED HELP WITH LATER - trying to animate between sampled and unsampled
# graphs!!!

animated_map <- county_wage_map %>%
  ggplot(aes(long, lat, group = group)) +
  geom_polygon(aes(fill = avg_wkly_wage_all)) + theme_void() +
  scale_fill_viridis_c(direction = -1, option = "D", name = "Weekly Wage",
                       na.value = "white") + 
  theme(plot.background = element_rect(fill = "#c4c4c4"), 
        legend.position = "bottom")
        

animated_map + 
  transition_manual(frames = c(state_county %in% county_wage_data, state_county %in% county_sample))
  


# test the map code for salary & covid data so they work in the Shiny app.

covid_map %>%
  
  # plot the graph using latitude and longitude from the states_map dataset.
  
  ggplot(aes(long, lat, group = group))+
  
  # fill the state outlines with cases_per_capita, and make the spaces in
  # between each state white.
  
  geom_polygon(aes(fill = cases_per_capita), color = "white") + 
  
  # edit the colors and direction of the color (so that cooler hues 
  # correspond to smaller case counts) and add labels to the graph.
  
  scale_fill_viridis_c(direction = -1, option = "A", 
                       name = "Total Cases per Capita") + 
  theme_void() + labs(
    title = "Total COVID-19 Cases per Capita by State, as of 10/16", 
    caption = "Source: New York Times")

salary_map %>%
  
  # use the same code as the covid data map, but with a different color palette,
  # different labels, and a different fill to correspond with the salary_map
  # dataframe.
  
  ggplot(aes(long, lat, group = group))+
  geom_polygon(aes(fill = value), color = "white") + theme_void() +
  scale_fill_viridis_c(direction = -1, option = "D", name = "Salary") + 
  labs(title = "Average Annual Teacher Salary by State, 2018-2019", 
    caption = "Source: National Center for Education Statistics")


# FUTURE DATA IDEAS:
# get gender data for teachers from total census - the acs dataset
# figure out how to map survey data links listed above.

# IGNORE

wages_map %>%
  ggplot(aes(long, lat, group = group))+
  geom_polygon(aes(fill = avg_ann_wage_all), color = "white") + 
  scale_fill_distiller(direction = 0) + theme_void()

```

